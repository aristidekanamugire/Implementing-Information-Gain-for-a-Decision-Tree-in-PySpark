{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aristidekanamugire/Implementing-Information-Gain-for-a-Decision-Tree-in-PySpark/blob/main/pyspark_decision_tree_info_gain_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2453952",
      "metadata": {
        "id": "c2453952"
      },
      "source": [
        "\n",
        "# Lab: Implementing Information Gain for a Decision Tree in PySpark\n",
        "\n",
        "In this lab, I will:\n",
        "\n",
        "1. Use PySpark DataFrames to load and preprocess a dataset.\n",
        "2. Implement **entropy** and **information gain** from scratch.\n",
        "3. Use your information gain function to choose the **best split** (a depth-1 decision tree, also called a decision stump).\n",
        "4. Evaluate your decision stump on a test set.\n",
        "\n",
        "I will use a simplified version of the **Titanic** dataset with a few features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1c3413c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1c3413c8",
        "outputId": "2e60a8f5-354c-45f7-ad69-93d0da55d479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark session created: <pyspark.sql.session.SparkSession object at 0x7f011459fd70>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Part 0 – Setup\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder.appName(\"DecisionTreeInfoGain\").getOrCreate()\n",
        "\n",
        "print(\"Spark session created:\", spark)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af925e4e",
      "metadata": {
        "id": "af925e4e"
      },
      "source": [
        "\n",
        "## Part 1 – Load and Simplify the Dataset\n",
        "\n",
        "We will keep only a few **categorical** or easy-to-discretize features to make the math cleaner:\n",
        "\n",
        "- Label: `Survived` (0/1)\n",
        "- Features: `Sex`, `Pclass`, `Embarked`\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "1. Update the path to point to your local copy of the Titanic CSV file.\n",
        "2. Run the code to load and inspect the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "91babcd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "91babcd3",
        "outputId": "4d72043e-3bf4-4a0c-9684-a863851e7e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+--------+-----+\n",
            "|   Sex|Pclass|Embarked|label|\n",
            "+------+------+--------+-----+\n",
            "|  male|     3|       S|    0|\n",
            "|female|     1|       C|    1|\n",
            "|female|     3|       S|    1|\n",
            "|female|     1|       S|    1|\n",
            "|  male|     3|       S|    0|\n",
            "+------+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            " |-- label: integer (nullable = true)\n",
            "\n",
            "Total rows: 889\n"
          ]
        }
      ],
      "source": [
        "titanic_path = \"/content/titanic.csv\"\n",
        "\n",
        "df = spark.read.csv(titanic_path, header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "cols = [\"Survived\", \"Sex\", \"Pclass\", \"Embarked\"]\n",
        "data = df.select(*cols)\n",
        "\n",
        "\n",
        "data = data.na.drop(subset=cols)\n",
        "\n",
        "\n",
        "data = data.withColumn(\"label\", col(\"Survived\").cast(\"int\")).drop(\"Survived\")\n",
        "\n",
        "data.show(5)\n",
        "data.printSchema()\n",
        "print(\"Total rows:\", data.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bb287d1",
      "metadata": {
        "id": "7bb287d1"
      },
      "source": [
        "\n",
        "## Part 2 – Train/Test Split\n",
        "\n",
        "We split the data into training and test sets so that we can evaluate how well our decision stump performs.\n",
        "\n",
        "**TODO:** Run the code below and record the number of rows in each split.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c744814e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c744814e",
        "outputId": "4792578c-5dfc-4a11-870f-125c753490ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rows: 744 Test rows: 145\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_df, test_df = data.randomSplit([0.8, 0.2], seed=42)\n",
        "print(\"Train rows:\", train_df.count(), \"Test rows:\", test_df.count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "189ab624",
      "metadata": {
        "id": "189ab624"
      },
      "source": [
        "\n",
        "## Part 3 – Entropy and Information Gain\n",
        "\n",
        "Recall:\n",
        "\n",
        "Let \\(Y\\) be the label (e.g., `Survived` = 0 or 1).\n",
        "\n",
        "- **Entropy of Y**:\n",
        "\n",
        "\\[\n",
        "H(Y) = -\\sum_y p(y) \\log_2 p(y)\n",
        "\\]\n",
        "\n",
        "If we split on a feature \\(X\\) (for example, `Sex` with values {male, female}):\n",
        "\n",
        "- **Conditional entropy**:\n",
        "\n",
        "\\[\n",
        "H(Y \\mid X) = \\sum_x p(x)\\, H(Y \\mid X = x)\n",
        "\\]\n",
        "\n",
        "- **Information Gain** of splitting on \\(X\\):\n",
        "\n",
        "\\[\n",
        "IG(Y, X) = H(Y) - H(Y \\mid X)\n",
        "\\]\n",
        "\n",
        "You will implement:\n",
        "\n",
        "1. A function to compute entropy from label counts.\n",
        "2. A function to compute information gain for a given feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d9daf530",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d9daf530",
        "outputId": "9c6f9ae1-8d45-4c05-8768-0a4bca9a0c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example label counts on training set: {1: 283, 0: 461}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import count\n",
        "\n",
        "def get_label_counts(df, label_col=\"label\"):\n",
        "    \"\"\"\n",
        "    Returns a dict: {label_value: count} for the given label column.\n",
        "    \"\"\"\n",
        "    counts = (\n",
        "        df.groupBy(label_col)\n",
        "          .agg(count(\"*\").alias(\"cnt\"))\n",
        "          .collect()\n",
        "    )\n",
        "    return {row[label_col]: row[\"cnt\"] for row in counts}\n",
        "\n",
        "# Example (you can test this):\n",
        "example_counts = get_label_counts(train_df, label_col=\"label\")\n",
        "print(\"Example label counts on training set:\", example_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fa3759",
      "metadata": {
        "id": "12fa3759"
      },
      "source": [
        "\n",
        "### 3.1 TODO – Implement Entropy\n",
        "\n",
        "Implement the function `entropy_from_counts(label_count_dict)` that takes a dictionary of label counts\n",
        "(e.g., `{0: 100, 1: 50}`) and returns the entropy in **bits**.\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Compute the total number of examples.\n",
        "2. For each label value, compute \\(p = \\text{count} / \\text{total}\\).\n",
        "3. Accumulate \\(-p \\log_2 p\\) across all labels (ignoring cases where \\(p = 0\\)).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c4161acf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c4161acf",
        "outputId": "a545e0c3-658d-4e52-b514-579e9ce613ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy of balanced 2-class distribution: 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import math\n",
        "\n",
        "def entropy_from_counts(label_count_dict):\n",
        "    total = sum(label_count_dict.values())\n",
        "    if total == 0:\n",
        "        return 0.0\n",
        "    entropy = 0.0\n",
        "    for count in label_count_dict.values():\n",
        "        if count > 0:\n",
        "            p = count / total\n",
        "            entropy -= p * math.log2(p)\n",
        "    return entropy\n",
        "\n",
        "# Testing\n",
        "test_counts = {0: 1, 1: 1}\n",
        "print(\"Entropy of balanced 2-class distribution:\", entropy_from_counts(test_counts))  # Should be 1.0\n",
        "\n",
        "\n",
        "# After implementing, you can test with a simple example:\n",
        "# For a perfectly balanced binary distribution {0: 1, 1: 1}, entropy should be 1.0 bit.\n",
        "# test_counts = {0: 1, 1: 1}\n",
        "# print(\"Entropy of balanced 2-class distribution:\", entropy_from_counts(test_counts))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "695cffc5",
      "metadata": {
        "id": "695cffc5"
      },
      "source": [
        "\n",
        "### 3.2 TODO – Implement Information Gain for a Feature\n",
        "\n",
        "Implement `information_gain(df, feature_col, label_col=\"label\")` to compute:\n",
        "\n",
        "\\[\n",
        "IG(Y, X) = H(Y) - H(Y \\mid X)\n",
        "\\]\n",
        "\n",
        "where:\n",
        "\n",
        "- \\(Y\\) is the label (column `label_col`),\n",
        "- \\(X\\) is a feature (column `feature_col`).\n",
        "\n",
        "Steps:\n",
        "\n",
        "1. Compute the **base entropy** \\(H(Y)\\) using the entire DataFrame.\n",
        "2. For each distinct value \\(v\\) of feature \\(X\\):\n",
        "   - Filter the DataFrame to `X == v`.\n",
        "   - Compute label counts and entropy \\(H(Y \\mid X = v)\\).\n",
        "   - Weight by \\(P(X = v) = \\text{count}(X=v) / \\text{total_rows}\\).\n",
        "3. Combine to obtain \\(H(Y \\mid X)\\), then return \\(IG = H(Y) - H(Y \\mid X)\\).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3d20a143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3d20a143",
        "outputId": "3ad95211-3934-464e-9bb8-f4f57143da5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IG for Sex: 0.2159099966074487\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def information_gain(df, feature_col, label_col=\"label\"):\n",
        "    total_rows = df.count()\n",
        "    if total_rows == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Base entropy H(Y)\n",
        "    base_counts = get_label_counts(df, label_col)\n",
        "    base_entropy = entropy_from_counts(base_counts)\n",
        "\n",
        "    # Conditional entropy H(Y|X)\n",
        "    conditional_entropy = 0.0\n",
        "    distinct_values = [row[feature_col] for row in df.select(feature_col).distinct().collect()]\n",
        "\n",
        "    for value in distinct_values:\n",
        "        subset = df.filter(col(feature_col) == value)\n",
        "        subset_size = subset.count()\n",
        "        if subset_size > 0:\n",
        "            weight = subset_size / total_rows\n",
        "            subset_counts = get_label_counts(subset, label_col)\n",
        "            subset_entropy = entropy_from_counts(subset_counts)\n",
        "            conditional_entropy += weight * subset_entropy\n",
        "\n",
        "    # Information Gain\n",
        "    return base_entropy - conditional_entropy\n",
        "\n",
        "# Quick test\n",
        "print(\"IG for Sex:\", information_gain(train_df, \"Sex\"))\n",
        "\n",
        "\n",
        "# After implementing, test with a simple call such as:\n",
        "# print(information_gain(train_df, feature_col=\"Sex\", label_col=\"label\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26710912",
      "metadata": {
        "id": "26710912"
      },
      "source": [
        "\n",
        "## Part 4 – Choose the Best Split (Decision Stump)\n",
        "\n",
        "Now use your `information_gain` function to compute the information gain of each candidate feature,\n",
        "and select the one with the highest information gain.\n",
        "\n",
        "Candidate features:\n",
        "\n",
        "- `Sex`\n",
        "- `Pclass`\n",
        "- `Embarked`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b06af742-ab38-46b5-a16f-7e1cba561784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b06af742-ab38-46b5-a16f-7e1cba561784",
        "outputId": "e3998403-97e1-45b0-c9f1-15d87c6972b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: Sex, Information Gain: 0.2159099966074487\n",
            "Feature: Pclass, Information Gain: 0.08094964875352906\n",
            "Feature: Embarked, Information Gain: 0.017456860135772523\n",
            "Best feature to split on: Sex with IG = 0.2159099966074487\n"
          ]
        }
      ],
      "source": [
        "\n",
        "candidate_features = [\"Sex\", \"Pclass\", \"Embarked\"]\n",
        "\n",
        "best_feature = None\n",
        "best_ig = float(\"-inf\")\n",
        "\n",
        "for feat in candidate_features:\n",
        "    ig = information_gain(train_df, feature_col=feat, label_col=\"label\")\n",
        "    print(f\"Feature: {feat}, Information Gain: {ig}\")\n",
        "    if ig > best_ig:\n",
        "        best_ig = ig\n",
        "        best_feature = feat\n",
        "\n",
        "print(\"Best feature to split on:\", best_feature, \"with IG =\", best_ig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c36fab0",
      "metadata": {
        "id": "3c36fab0"
      },
      "source": [
        "\n",
        "## Part 5 – Build a Tiny Decision Tree (Decision Stump)\n",
        "\n",
        "We will build a depth-1 decision tree that:\n",
        "\n",
        "- Splits on the **best feature** you found.\n",
        "- For each value of that feature, predicts the **majority label** among training examples with that value.\n",
        "\n",
        "### 5.1 Compute Majority Label per Feature Value\n",
        "\n",
        "`majority_map` from `feature_value -> majority_label`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a432b182",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a432b182",
        "outputId": "3a87a34b-9020-4c7f-8d73-935a2bd8bcbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using best feature: Sex\n",
            "+------+-----+---+\n",
            "|   Sex|label|cnt|\n",
            "+------+-----+---+\n",
            "|female|    1|194|\n",
            "|female|    0| 70|\n",
            "|  male|    0|391|\n",
            "|  male|    1| 89|\n",
            "+------+-----+---+\n",
            "\n",
            "Majority map: {'female': 1, 'male': 0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import desc\n",
        "\n",
        "print(\"Using best feature:\", best_feature)\n",
        "\n",
        "# Group by the best feature and label, count how many of each\n",
        "value_majorities = (\n",
        "    train_df.groupBy(best_feature, \"label\")\n",
        "            .agg(count(\"*\").alias(\"cnt\"))\n",
        "            .orderBy(best_feature, desc(\"cnt\"))\n",
        ")\n",
        "\n",
        "value_majorities.show()\n",
        "\n",
        "# Build majority_map such that for each distinct value v of best_feature,\n",
        "# majority_map[v] = majority label (0 or 1) that appears most in the training set.\n",
        "majority_map = {}\n",
        "\n",
        "rows = value_majorities.collect()\n",
        "for row in rows:\n",
        "    v = row[best_feature]\n",
        "    lbl = row[\"label\"]\n",
        "    # The first time we see a feature value v, it will correspond to the\n",
        "    # label with the highest count (because of the descending sort).\n",
        "    if v not in majority_map:\n",
        "        majority_map[v] = lbl\n",
        "\n",
        "print(\"Majority map:\", majority_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dad7be5",
      "metadata": {
        "id": "6dad7be5"
      },
      "source": [
        "\n",
        "### 5.2 Apply the Decision Stump to the Test Set\n",
        "\n",
        "We now define a simple prediction function using `majority_map` and apply it to the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0a056283",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0a056283",
        "outputId": "7da03d37-e8de-467c-b997-ff89b137a64c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+----------+\n",
            "|Sex   |label|prediction|\n",
            "+------+-----+----------+\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|0    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "|female|1    |1         |\n",
            "+------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "def stump_predict(value):\n",
        "    \"\"\"\n",
        "    Predict the label based on the majority_map for the given feature value.\n",
        "    If the feature value has not been seen in training, default to 0.\n",
        "    \"\"\"\n",
        "    return int(majority_map.get(value, 0))\n",
        "\n",
        "stump_udf = udf(stump_predict, IntegerType())\n",
        "\n",
        "pred_test = test_df.withColumn(\n",
        "    \"prediction\",\n",
        "    stump_udf(col(best_feature))\n",
        ")\n",
        "\n",
        "pred_test.select(best_feature, \"label\", \"prediction\").show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179acafb",
      "metadata": {
        "id": "179acafb"
      },
      "source": [
        "\n",
        "## Part 6 – Evaluate the Accuracy of Your Decision Stump\n",
        "\n",
        "Compute the accuracy on the test set by comparing `label` with `prediction`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "086a2747",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "086a2747",
        "outputId": "054a875f-46a7-466e-8125-cf2961c1870e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision stump using feature 'Sex'\n",
            "Accuracy on test set: 0.786\n"
          ]
        }
      ],
      "source": [
        "\n",
        "correct = pred_test.filter(col(\"label\") == col(\"prediction\")).count()\n",
        "total = pred_test.count()\n",
        "accuracy = correct / total if total > 0 else 0.0\n",
        "\n",
        "print(f\"Decision stump using feature '{best_feature}'\")\n",
        "print(f\"Accuracy on test set: {accuracy:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82ab10d6",
      "metadata": {
        "id": "82ab10d6"
      },
      "source": [
        "\n",
        "## Reflection Questions\n",
        "\n",
        "Answer these questions in a markdown cell or in your lab report:\n",
        "\n",
        "1. Which feature had the highest information gain? Does this match your intuition about what mattered most for survival on the Titanic?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "  - Sex (Information Gain ≈ 0.217–0.220).  \n",
        "  - Yes, this matches intuition: on the Titanic, women had a dramatically higher survival rate than men (\"women and children first\").\n",
        "\n",
        "\n",
        "2. What accuracy did your decision stump achieve on the test set?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "  - Approximately **0.78 – 0.80** (78–80%), depending on the exact random split.  \n",
        "   This is very good for a single binary split!\n",
        "\n",
        "\n",
        "3. How do you think using a **deeper decision tree** (with more levels) would affect:\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "  - Training accuracy: Would increase (possibly to 100%) because deeper trees can fit the training data perfectly.\n",
        "\n",
        "  - Risk of overfitting: Would increase significantly. A very deep tree may memorize noise and perform worse on unseen data.\n",
        "\n",
        "\n",
        "4. What limitations do you see in using a single split (decision stump) for this problem?\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "\n",
        "  - Can only capture one interaction (e.g., only \"Sex matters\").  \n",
        "  - Cannot model combined effects (e.g., \"1st-class women survived almost always, but 3rd-class men almost never\").  \n",
        "  - Lower expressive power than full trees → lower accuracy ceiling.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0rc2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}